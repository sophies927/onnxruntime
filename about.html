<!DOCTYPE html>
<html lang="en">

<head>
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-156955408-1"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());
        gtag('config', 'UA-156955408-1');
    </script>

    <script type="text/javascript" src="https://js.monitor.azure.com/scripts/c/ms.analytics-web-3.min.js">
    </script>

    <script type="text/javascript">
        const analytics = new oneDS.ApplicationInsights();
        var config = {
            instrumentationKey: "360b0e675e0044398fd28c8bdf711b8e-1fe5434d-ee99-4837-99cc-a3a16462d82d-7262",
            channelConfiguration: { // Post channel configuration
                eventsLimitInMem: 50
            },
            propertyConfiguration: { // Properties Plugin configuration 
                env: "PPE" // Environment can be set to PPE or PROD as needed. 
            },
            webAnalyticsConfiguration: { // Web Analytics Plugin configuration
                //urlCollectQuery:true, 
                autoCapture: {
                    scroll: true,
                    pageView: true,
                    onLoad: true,
                    onUnload: true,
                    click: true,
                    resize: true,
                    jsError: true
                }
            }
        };
        //Initialize SDK
        analytics.initialize(config, []);
    </script>

    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <title>ONNX Runtime | About</title>
    <link rel="icon" href="./images/ONNXRuntime-Favicon.png" type="image/gif" sizes="16x16">
    <link rel="stylesheet" href="css/fonts.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/bootstrap/4.6.2/css/bootstrap.min.css"
integrity="sha512-rt/SrQ4UNIaGfDyEXZtNcyWvQeOq0QLygHluFQcSjaGB04IxWhal71tKuzP6K8eYXYB6vJV4pHkXcmFGGQ1/0w=="
crossorigin="anonymous" referrerpolicy="no-referrer" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css"
integrity="sha512-iecdLmaskl7CVkqkXNQ/ZH/XLlvWZOJyj7Yy7tcenmpD1ypASozpmT/E0iPtmFIB46ZmdtAc9eNBvH0H/ZpiBw=="
crossorigin="anonymous" referrerpolicy="no-referrer" />
    <link rel="stylesheet" href="css/custom.css">
    <link rel="stylesheet" href="css/responsive.css">
</head>

<body>
    <a class="skip-main" href="#skipMain">Skip to main content</a>
    <div class="main-wrapper">
        <div class="top-banner-bg">

            <!-- Partial header.html Start-->
            <div w3-include-html="header.html"></div>
            <!-- Partial header.html End-->

            <div id="skipMain" role="main">
                <div class="outer-container mx-auto py-5">
                    <section class="blue-title-columns py-md-5 pb-4 pt-4 mt-5">
                        <div class="container-fluid">
                            <div class="row">
                                <div class="col-12 col-md-9">
                                    <h1 class="mb-3 blue-text">About</h1>
                                    <p class="mb-2">
                                        ONNX Runtime is an open source project that is designed to accelerate machine learning across a wide range of frameworks, operating systems, and hardware platforms. It enables acceleration of machine learning inferencing across all of your deployment targets using a single set of <abbr title="Application Program Interface">API</abbr>. ONNX Runtime automatically parses through your model to identify optimization opportunities and provides access to the best hardware acceleration available.
                                    </p>
                                    <p class="mb-2">
                                        ONNX Runtime also offers training acceleration, which incorporates innovations from Microsoft Research and is proven across production workloads like Office 365, Bing and Visual Studio.
                                    </p>
                                    <a href="https://github.com/microsoft/onnxruntime" target="_blank" class="link ft-20"><span class="link-content">Join us on Github</span><span class="link-arrow fa fa-angle-right"></span></a>
                                    <br/> <br/>
                                    <p class="mb-2">
                                       At Microsoft, ONNX Runtime is used as the primary Machine Learning inferencing solution for products groups. ONNX Runtime serves over 1 trillion daily inferences across over 150 production models covering all task domains.
                                    </p>
                        
                                    <a href="ort-at-microsoft.html" target="_blank" class="link ft-20"><span class="link-content">Learn more about ONNX Runtime at Microsoft</span><span class="link-arrow fa fa-angle-right"></span></a>

                                </div>
                                <div class="col-12 col-md-3 d-none d-md-block">
                                    <img src="./images/ONNX-Icon.png" alt="ONNX Runtime Logo Icon" class="img-fluid">
                                </div>
                            </div>
                        </div>
                    </section>
                    <section class="py-md-5 pb-4 pt-4 blue-title-columns border-top">
                        <div class="container-fluid">
                            <div class="row pb-4 pb-md-5">
                                <div class="col-12 col-md-6 mb-4 mb-md-0 text-center pr-10">
                                    <img src="./images/optimization-acceleration.png" alt="Illustration of a computational graph representing ONNX format and the acceleration enabled by ONNX Runtime" class="img-fluid">
                                </div>
                                <div class="col-12 col-md-6 pr-10">
                                    <h2>Optimization and acceleration</h2>
                                    <p>
                                        Run any ONNX model using a single set of inference <a href="https://www.onnxruntime.ai/docs/api/" target="_blank" class="link"><abbr title="Application Program Interface">API</abbr>s</a> that provide access to the best hardware acceleration available. Built-in optimization features trim and consolidate nodes without impacting model accuracy. Additionally, full backwards <a href="https://www.onnxruntime.ai/docs/reference/compatibility.html" target="_blank" class="link">compatibility</a> for ONNX and ONNX-<abbr>ML</abbr> ensures all ONNX models can be inferenced.
                                    </p>
                                </div>
                            </div>
                            <div class="row pb-0 pt-0 py-lg-5">
                                <div class="col-12 col-md-6 order-md-2 mb-4 mb-md-0 text-center pr-10">
                                    <img src="./images/API-platform-support.png" alt="Illustration of blank boxes conveying the breadth of API and platform support" class="img-fluid">
                                </div>
                                <div class="col-12 col-md-6 order-md-1 pr-10">
                                    <h2><abbr title="Application Program Interface">API</abbr> and platform support</h2>
                                    <p>
                                        Take advantage of the benefits of ONNX Runtime without changing your technology stack. Access ONNX Runtime using your preferred <a href="https://www.onnxruntime.ai/docs/api/" target="_blank" class="link"><abbr title="Application Program Interface">API</abbr></a> &mdash; <abbr>C#</abbr>, <abbr>C++</abbr>, C, Python, or Java. Support for Linux, Windows and Mac allows you to build and deploy applications without worry.
                                    </p>
                                </div>
                            </div>
                            <div class="row pt-4 pt-md-5">
                                <div class="col-12 col-md-6 mb-4 mb-md-0 text-center pr-10">
                                    <img src="./images/continuous-community-innovation.png" alt="Illustration of a lightbulb above three computers, all connected by lines; represents the community of ONNX Runtime contributors" class="img-fluid">
                                </div>
                                <div class="col-12 col-md-6 pr-10">
                                    <h2>Continuous community innovation</h2>
                                    <p>
                                        Our community of partners and contributors drives constant innovation. Partners provide ONNX compatible compilers and accelerators to ensure models are as efficient as possible. Our contributor community improves ONNX Runtime by contributing code, ideas and feedback. Join us on <a href="https://github.com/Microsoft/onnxruntime" target="_blank" class="link">GitHub</a>.
                                    </p>
                                </div>
                            </div>
                        </div>
                    </section>
                </div>

                <section class="py-md-5 pt-4 pb-4 bg-lightgray">
                    <div class="outer-container mx-auto">
                        <div class="container-fluid blue-title-columns">
                            <div class="row">
                                <div class="col-12">
                                    <h2 class="mt-3 mt-md-0">Design principles</h2>
                                    <p class="mb-md-0 pr-0 pr-md-5">
                                        ONNX Runtime abstracts custom accelerators and runtimes to maximize their benefits across an ONNX model. To do this, ONNX Runtime partitions the ONNX model graph into subgraphs that align with available custom accelerators and runtimes. When operators are not supported by custom accelerators or runtimes, ONNX Runtime provides a default runtime that is used as the fallback execution &mdash; ensuring that any model will run. <a href="docs/reference/high-level-design.html" target="_blank" class="link">Learn more</a>.
                                    </p>
                                </div>
                            </div>
                        </div>
                    </div>
                </section>
            </div>
        </div>
    </div>
    <!-- Partial footer.html Start-->
    <div w3-include-html="footer.html"></div>
    <!-- Partial footer.html End-->

    <a id="back-to-top" href="JavaScript:void(0);" class="btn btn-lg back-to-top" role="button" aria-label="Back to top"><span class="fa fa-angle-up"></span></a>

    <script src="./js/w3.js"></script>
    <script>w3.includeHTML();</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.7.0/jquery.min.js"
	integrity="sha512-3gJwYpMe3QewGELv8k/BX9vcqhryRdzRMxVfq6ngyWXwo03GFEzjsUm8Q7RZcHPHksttq7/GFoxjCVUjkjvPdw=="
	crossorigin="anonymous" referrerpolicy="no-referrer"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/bootstrap/4.6.2/js/bootstrap.min.js"
	integrity="sha512-7rusk8kGPFynZWu26OKbTeI+QPoYchtxsmPeBqkHIEXJxeun4yJ4ISYe7C6sz9wdxeE1Gk3VxsIWgCZTc+vX3g=="
	crossorigin="anonymous" referrerpolicy="no-referrer"></script>
    <script src="./js/custom.js"></script>

</body>

</html>